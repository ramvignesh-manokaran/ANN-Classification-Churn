{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "efbf976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "046d4f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       RowNumber  CustomerId    Surname  ...  IsActiveMember EstimatedSalary Exited\n",
       "0             1    15634602   Hargrave  ...               1       101348.88      1\n",
       "1             2    15647311       Hill  ...               1       112542.58      0\n",
       "2             3    15619304       Onio  ...               0       113931.57      1\n",
       "3             4    15701354       Boni  ...               0        93826.63      0\n",
       "4             5    15737888   Mitchell  ...               1        79084.10      0\n",
       "...         ...         ...        ...  ...             ...             ...    ...\n",
       "9995       9996    15606229   Obijiaku  ...               0        96270.64      0\n",
       "9996       9997    15569892  Johnstone  ...               1       101699.77      0\n",
       "9997       9998    15584532        Liu  ...               1        42085.58      1\n",
       "9998       9999    15682355  Sabbatini  ...               0        92888.52      1\n",
       "9999      10000    15628319     Walker  ...               0        38190.78      0\n",
       "\n",
       "[10000 rows x 14 columns]>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('Churn_Modelling.csv')\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5fc35859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "377aa179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b64ad06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Geography_France  Geography_Germany  Geography_Spain\n",
       "0                  1.0                0.0              0.0\n",
       "1                  0.0                0.0              1.0\n",
       "2                  1.0                0.0              0.0\n",
       "3                  1.0                0.0              0.0\n",
       "4                  0.0                0.0              1.0\n",
       "...                ...                ...              ...\n",
       "9995               1.0                0.0              0.0\n",
       "9996               1.0                0.0              0.0\n",
       "9997               1.0                0.0              0.0\n",
       "9998               0.0                1.0              0.0\n",
       "9999               1.0                0.0              0.0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode 'Geography'\n",
    "one_hot_encoder_geo = OneHotEncoder(handle_unknown='ignore')\n",
    "geo_encoded = one_hot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoded_df = pd.DataFrame(geo_encoded, columns=one_hot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "geo_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9b0fe91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  ...  Geography_Germany  Geography_Spain\n",
       "0          619       0  ...                0.0              0.0\n",
       "1          608       0  ...                0.0              1.0\n",
       "2          502       0  ...                0.0              0.0\n",
       "3          699       0  ...                0.0              0.0\n",
       "4          850       0  ...                0.0              1.0\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the encoded columns with the original data\n",
    "data = pd.concat([data, geo_encoded_df], axis=1)\n",
    "data = data.drop(['Geography'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bfbd155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = data.drop('EstimatedSalary', axis=1)\n",
    "y = data['EstimatedSalary']\n",
    "\n",
    "## Split the features and target variable into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2112be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the encoders and scalers for future use\n",
    "\n",
    "with open('label_encoder_gender.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open('one_hot_encoder_geo.pkl', 'wb') as file:\n",
    "    pickle.dump(one_hot_encoder_geo, file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e156ce20",
   "metadata": {},
   "source": [
    "### ANN Regression Problem Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bcccecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5d605e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 64)                832       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2945 (11.50 KB)\n",
      "Trainable params: 2945 (11.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the ANN model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression. Linear activation is default for regression tasks\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae']) # Compile the model with MAE loss for regression\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9dc41927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Set up TensorBoard logging\n",
    "log_dir = \"regressions/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91a39728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "158c8d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 2s 7ms/step - loss: 100000.6719 - mae: 100000.6719 - val_loss: 102116.1328 - val_mae: 102116.1328\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 99938.3203 - mae: 99938.3203 - val_loss: 101995.7578 - val_mae: 101995.7578\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 99751.4609 - mae: 99751.4609 - val_loss: 101753.7109 - val_mae: 101753.7109\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 99445.0391 - mae: 99445.0391 - val_loss: 101419.3281 - val_mae: 101419.3281\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 99055.5391 - mae: 99055.5391 - val_loss: 101015.8594 - val_mae: 101015.8594\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 98612.4297 - mae: 98612.4297 - val_loss: 100568.9062 - val_mae: 100568.9062\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 98167.9297 - mae: 98167.9297 - val_loss: 100142.8594 - val_mae: 100142.8594\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 97754.8125 - mae: 97754.8125 - val_loss: 99751.2500 - val_mae: 99751.2500\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 97359.2031 - mae: 97359.2031 - val_loss: 99406.4062 - val_mae: 99406.4062\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 97052.6719 - mae: 97052.6719 - val_loss: 99075.3984 - val_mae: 99075.3984\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 96721.7734 - mae: 96721.7734 - val_loss: 98737.9531 - val_mae: 98737.9531\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 96367.4922 - mae: 96367.4922 - val_loss: 98352.7734 - val_mae: 98352.7734\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 95954.8125 - mae: 95954.8125 - val_loss: 97919.2422 - val_mae: 97919.2422\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 95487.5078 - mae: 95487.5078 - val_loss: 97423.4297 - val_mae: 97423.4297\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 94996.4609 - mae: 94996.4609 - val_loss: 96925.5078 - val_mae: 96925.5078\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 94483.6172 - mae: 94483.6172 - val_loss: 96392.7734 - val_mae: 96392.7734\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 93959.7266 - mae: 93959.7266 - val_loss: 95879.0078 - val_mae: 95879.0078\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 93448.3203 - mae: 93448.3203 - val_loss: 95358.8438 - val_mae: 95358.8438\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 92960.8203 - mae: 92960.8203 - val_loss: 94869.1562 - val_mae: 94869.1562\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 92474.1562 - mae: 92474.1562 - val_loss: 94364.9688 - val_mae: 94364.9688\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 91987.3828 - mae: 91987.3828 - val_loss: 93857.2734 - val_mae: 93857.2734\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 91500.9219 - mae: 91500.9219 - val_loss: 93383.2891 - val_mae: 93383.2891\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 91013.1172 - mae: 91013.1172 - val_loss: 92915.2812 - val_mae: 92915.2812\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 90544.0781 - mae: 90544.0781 - val_loss: 92433.3438 - val_mae: 92433.3438\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 90057.1406 - mae: 90057.1406 - val_loss: 91947.0078 - val_mae: 91947.0078\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 89576.6875 - mae: 89576.6875 - val_loss: 91449.6328 - val_mae: 91449.6328\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 89097.9531 - mae: 89097.9531 - val_loss: 90959.2031 - val_mae: 90959.2031\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 88603.3906 - mae: 88603.3906 - val_loss: 90462.4219 - val_mae: 90462.4219\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 88113.0391 - mae: 88113.0391 - val_loss: 89944.6719 - val_mae: 89944.6719\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 87634.5469 - mae: 87634.5469 - val_loss: 89466.8281 - val_mae: 89466.8281\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 87154.5469 - mae: 87154.5469 - val_loss: 88972.5469 - val_mae: 88972.5469\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 86658.6562 - mae: 86658.6562 - val_loss: 88495.5625 - val_mae: 88495.5625\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 86169.8906 - mae: 86169.8906 - val_loss: 88014.4766 - val_mae: 88014.4766\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 85687.6172 - mae: 85687.6172 - val_loss: 87474.9375 - val_mae: 87474.9375\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 85195.1562 - mae: 85195.1562 - val_loss: 86963.4219 - val_mae: 86963.4219\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 84698.9609 - mae: 84698.9609 - val_loss: 86489.4609 - val_mae: 86489.4609\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 84221.1172 - mae: 84221.1172 - val_loss: 85977.1484 - val_mae: 85977.1484\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 83728.5625 - mae: 83728.5625 - val_loss: 85569.9609 - val_mae: 85569.9609\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 83260.3359 - mae: 83260.3359 - val_loss: 84961.6875 - val_mae: 84961.6875\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 82777.8906 - mae: 82777.8906 - val_loss: 84484.8594 - val_mae: 84484.8594\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 82298.3828 - mae: 82298.3828 - val_loss: 83986.3203 - val_mae: 83986.3203\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 81806.1172 - mae: 81806.1172 - val_loss: 83484.5547 - val_mae: 83484.5547\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 81308.1719 - mae: 81308.1719 - val_loss: 82963.5469 - val_mae: 82963.5469\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 80825.8281 - mae: 80825.8281 - val_loss: 82484.2266 - val_mae: 82484.2266\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 80337.7578 - mae: 80337.7578 - val_loss: 82037.5703 - val_mae: 82037.5703\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 79854.7188 - mae: 79854.7188 - val_loss: 81519.7109 - val_mae: 81519.7109\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 79368.0781 - mae: 79368.0781 - val_loss: 80979.1562 - val_mae: 80979.1562\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 78903.8984 - mae: 78903.8984 - val_loss: 80486.8047 - val_mae: 80486.8047\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 78399.7969 - mae: 78399.7969 - val_loss: 79997.0625 - val_mae: 79997.0625\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 77908.1797 - mae: 77908.1797 - val_loss: 79487.8672 - val_mae: 79487.8672\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 77444.3906 - mae: 77444.3906 - val_loss: 79060.2188 - val_mae: 79060.2188\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 76965.4062 - mae: 76965.4062 - val_loss: 78629.6953 - val_mae: 78629.6953\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 76478.4062 - mae: 76478.4062 - val_loss: 78107.9766 - val_mae: 78107.9766\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 76020.9531 - mae: 76020.9531 - val_loss: 77554.5078 - val_mae: 77554.5078\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 75575.8594 - mae: 75575.8594 - val_loss: 77090.0000 - val_mae: 77090.0000\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 75071.6250 - mae: 75071.6250 - val_loss: 76632.8203 - val_mae: 76632.8203\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 74601.4141 - mae: 74601.4141 - val_loss: 76187.3438 - val_mae: 76187.3438\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 74157.7969 - mae: 74157.7969 - val_loss: 75666.6797 - val_mae: 75666.6797\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 73656.9688 - mae: 73656.9688 - val_loss: 75124.2578 - val_mae: 75124.2578\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 73194.0703 - mae: 73194.0703 - val_loss: 74633.0312 - val_mae: 74633.0312\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 72737.0312 - mae: 72737.0312 - val_loss: 74164.7578 - val_mae: 74164.7578\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 72269.4375 - mae: 72269.4375 - val_loss: 73695.9531 - val_mae: 73695.9531\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 71804.0312 - mae: 71804.0312 - val_loss: 73225.7031 - val_mae: 73225.7031\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 71359.3125 - mae: 71359.3125 - val_loss: 72744.2344 - val_mae: 72744.2344\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 70898.0391 - mae: 70898.0391 - val_loss: 72283.2891 - val_mae: 72283.2891\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 70485.2812 - mae: 70485.2812 - val_loss: 71802.4531 - val_mae: 71802.4531\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 70020.0781 - mae: 70020.0781 - val_loss: 71335.2969 - val_mae: 71335.2969\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 69584.8438 - mae: 69584.8438 - val_loss: 70923.1953 - val_mae: 70923.1953\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 69132.1797 - mae: 69132.1797 - val_loss: 70442.3438 - val_mae: 70442.3438\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 68693.7969 - mae: 68693.7969 - val_loss: 70038.2188 - val_mae: 70038.2188\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 68276.7109 - mae: 68276.7109 - val_loss: 69469.0234 - val_mae: 69469.0234\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 67831.2578 - mae: 67831.2578 - val_loss: 69129.2266 - val_mae: 69129.2266\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 67419.5312 - mae: 67419.5312 - val_loss: 68651.8125 - val_mae: 68651.8125\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 66974.0781 - mae: 66974.0781 - val_loss: 68155.6172 - val_mae: 68155.6172\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 66565.8672 - mae: 66565.8672 - val_loss: 67733.9844 - val_mae: 67733.9844\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 66158.5781 - mae: 66158.5781 - val_loss: 67247.8672 - val_mae: 67247.8672\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 65694.4844 - mae: 65694.4844 - val_loss: 67054.1016 - val_mae: 67054.1016\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 65305.2539 - mae: 65305.2539 - val_loss: 66373.4219 - val_mae: 66373.4219\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 64908.4766 - mae: 64908.4766 - val_loss: 66006.2656 - val_mae: 66006.2656\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 64501.8086 - mae: 64501.8086 - val_loss: 65635.3359 - val_mae: 65635.3359\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 64097.1094 - mae: 64097.1094 - val_loss: 65139.8945 - val_mae: 65139.8945\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 63670.6367 - mae: 63670.6367 - val_loss: 64696.0469 - val_mae: 64696.0469\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 63301.0352 - mae: 63301.0352 - val_loss: 64255.2500 - val_mae: 64255.2500\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 62903.4414 - mae: 62903.4414 - val_loss: 63947.4844 - val_mae: 63947.4844\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 62514.5352 - mae: 62514.5352 - val_loss: 63425.6055 - val_mae: 63425.6055\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 62111.6250 - mae: 62111.6250 - val_loss: 63023.0117 - val_mae: 63023.0117\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 61740.3164 - mae: 61740.3164 - val_loss: 62626.8516 - val_mae: 62626.8516\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 61326.4219 - mae: 61326.4219 - val_loss: 62229.1055 - val_mae: 62229.1055\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 60963.8750 - mae: 60963.8750 - val_loss: 61821.7891 - val_mae: 61821.7891\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 60600.4492 - mae: 60600.4492 - val_loss: 61555.2148 - val_mae: 61555.2148\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 60247.8086 - mae: 60247.8086 - val_loss: 61063.8906 - val_mae: 61063.8906\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 59852.3945 - mae: 59852.3945 - val_loss: 60737.6836 - val_mae: 60737.6836\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 59519.7383 - mae: 59519.7383 - val_loss: 60320.5781 - val_mae: 60320.5781\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 59195.4219 - mae: 59195.4219 - val_loss: 59991.7500 - val_mae: 59991.7500\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 58829.7188 - mae: 58829.7188 - val_loss: 59594.0156 - val_mae: 59594.0156\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 58496.9297 - mae: 58496.9297 - val_loss: 59242.1914 - val_mae: 59242.1914\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 58147.2148 - mae: 58147.2148 - val_loss: 58952.6914 - val_mae: 58952.6914\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 57866.5859 - mae: 57866.5859 - val_loss: 58582.5547 - val_mae: 58582.5547\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 57535.3633 - mae: 57535.3633 - val_loss: 58236.2695 - val_mae: 58236.2695\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 57236.7617 - mae: 57236.7617 - val_loss: 57922.7891 - val_mae: 57922.7891\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping, tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "66c712f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 80710), started 0:18:53 ago. (Use '!kill 80710' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7b60dde1088707dc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7b60dde1088707dc\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir regressions/logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f8d0337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard should be accessible at: http://localhost:6007\n",
      "If the iframe above doesn't work, click this link or copy-paste the URL into your browser:\n",
      "http://localhost:6007\n",
      "\n",
      "✅ TensorBoard is running on port 6007\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Open TensorBoard in browser\n",
    "import webbrowser\n",
    "import time\n",
    "\n",
    "print(\"TensorBoard should be accessible at: http://localhost:6007\")\n",
    "print(\"If the iframe above doesn't work, click this link or copy-paste the URL into your browser:\")\n",
    "print(\"http://localhost:6007\")\n",
    "\n",
    "# Optionally, automatically open in browser\n",
    "# webbrowser.open('http://localhost:6007')\n",
    "\n",
    "# Check if TensorBoard is running\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run(['lsof', '-i', ':6007'], capture_output=True, text=True)\n",
    "    if result.stdout:\n",
    "        print(\"\\n✅ TensorBoard is running on port 6007\")\n",
    "    else:\n",
    "        print(\"\\n❌ TensorBoard might not be running on port 6007\")\n",
    "except:\n",
    "    print(\"\\nCouldn't check port status, but TensorBoard should be running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b054677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 5ms/step - loss: 56339.1992 - mae: 56339.1992\n",
      "Test Loss: 56339.19921875, Test MAE: 56339.19921875\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the model\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "262117b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a825765/Documents/me/NUS/Learn/Machine Learning/ANN/venv/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('salary_regression_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60660d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
